{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well can QML classify classical datasets? In this [paper[1]](https://arxiv.org/abs/2108.00661), we use various *Quantum Convolutional Neural Networks (QCNN)* for image data classification tasks. We benchmarked various QCNN models differentiated by structures of parameterized quantum circuits, quantum data encoding methods, classical data pre-processing methods, cost functions and optimizers on MNIST and Fashion MNIST datasets. This is a introductory tutorial for the paper and the full code can be found in this [Github repo](https://github.com/takh04/QCNN).\n",
    "\n",
    "QCNN is a local and translationally invariant variational quantum model suggested by [Cong et al.[2]](https://arxiv.org/abs/1810.03787). One of the key feature of QCNN is it reduces the number of qubit each layer. Due to its similarity with classical convolutional neural networks, people often use the term convolutional and pooling layers. The original work uses QCNN to classify quantum data in quantum phase recognition problem. Here, we will focus on classifying classical data.\n",
    "\n",
    "*This tutorial was tested under following environment*:\n",
    "```\n",
    "python==3.10\n",
    "pennylane==0.27.0\n",
    "tensorflow==2.19.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text for the image](QCNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tak/anaconda3/envs/new/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train[..., np.newaxis] / 255.0, x_test[..., np.newaxis] / 255.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter class 0 and 1 of MNIST dataset for binary classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_filter_01 = np.where((y_train == 0) | (y_train == 1))\n",
    "x_test_filter_01 = np.where((y_test == 0) | (y_test == 1))\n",
    "\n",
    "X_train, X_test = x_train[x_train_filter_01], x_test[x_test_filter_01]\n",
    "Y_train, Y_test = y_train[x_train_filter_01], y_test[x_test_filter_01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize 28 by 28 image into 256 dimensional vectors so we can fit into 8 qubit QCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.image.resize(X_train[:], (256, 1)).numpy()\n",
    "X_test = tf.image.resize(X_test[:], (256, 1)).numpy()\n",
    "X_train, X_test = tf.squeeze(X_train).numpy(), tf.squeeze(X_test).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Quantum Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process classical data with quantum hardware, we must first map classical data in a quantum state. Here, we will use Amplitude Embedding scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_embedding(X):\n",
    "    qml.AmplitudeEmbedding(X, wires=range(8), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Unitary Ansatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QCNN model utilizes local trainable unitaries. Here, we are interested in *2-local* architecture. Below is parameterized circuit that can express general *SU4* unitaries with 15 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_SU4(params, wires): # 15 params\n",
    "    qml.U3(params[0], params[1], params[2], wires=wires[0])\n",
    "    qml.U3(params[3], params[4], params[5], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.RY(params[6], wires=wires[0])\n",
    "    qml.RZ(params[7], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[8], wires=wires[0])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.U3(params[9], params[10], params[11], wires=wires[0])\n",
    "    qml.U3(params[12], params[13], params[14], wires=wires[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. QCNN Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will define a QCNN structure. For convolutional layer, we will consider all two nearest neighbour two qubit unitaries. We will assume periodic boundary condition where the first qubit and the last qubits are connected as well. For the pooling layer, we will trace out the qubits without applying any additional gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer1(U, params):\n",
    "    U(params, wires=[0, 7])\n",
    "    for i in range(0, 8, 2):\n",
    "        U(params, wires=[i, i + 1])\n",
    "    for i in range(1, 7, 2):\n",
    "        U(params, wires=[i, i + 1])\n",
    "def conv_layer2(U, params):\n",
    "    U(params, wires=[0, 6])\n",
    "    U(params, wires=[0, 2])\n",
    "    U(params, wires=[4, 6])\n",
    "    U(params, wires=[2, 4])\n",
    "def conv_layer3(U, params):\n",
    "    U(params, wires=[0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QCNN_structure_without_pooling(U, params):\n",
    "    param1 = params[0:15]\n",
    "    param2 = params[15:30]\n",
    "    param3 = params[30:45]\n",
    "\n",
    "    conv_layer1(U, param1)\n",
    "    conv_layer2(U, param2)\n",
    "    conv_layer3(U, param3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full QCNN model can be constructed by concatenating data embedding, QCNN ansatz, and measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires = 8)\n",
    "@qml.qnode(dev)\n",
    "def QCNN(X, params):\n",
    "\n",
    "    data_embedding(X)\n",
    "    QCNN_structure_without_pooling(U_SU4, params)\n",
    "    result = qml.expval(qml.PauliZ(4))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train QCNN model with MSE loss fucntion. Here, we will train for 100 steps, with batch size 25 and learning rate 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, X, Y):\n",
    "    predictions = [QCNN(x, params) for x in X]\n",
    "    loss = square_loss(Y, predictions)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tak/anaconda3/envs/new/lib/python3.10/site-packages/autograd/numpy/numpy_vjps.py:943: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  onp.add.at(A, idx, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  cost:  0.44686799204947114\n",
      "iteration:  10  cost:  0.29208977354527255\n",
      "iteration:  20  cost:  0.37411009764285796\n",
      "iteration:  30  cost:  0.27463692530358796\n",
      "iteration:  40  cost:  0.18627018190756262\n",
      "iteration:  50  cost:  0.0803754591165053\n",
      "iteration:  60  cost:  0.1137624847960277\n",
      "iteration:  70  cost:  0.08537221852104945\n",
      "iteration:  80  cost:  0.06860804023485788\n",
      "iteration:  90  cost:  0.0806990055170192\n"
     ]
    }
   ],
   "source": [
    "steps = 100\n",
    "learning_rate = 0.01\n",
    "batch_size = 25\n",
    "\n",
    "\n",
    "params = np.random.randn(45, requires_grad=True)\n",
    "opt = qml.NesterovMomentumOptimizer(stepsize=learning_rate)\n",
    "loss_history = []\n",
    "\n",
    "for it in range(steps):\n",
    "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "    X_batch = [X_train[i] for i in batch_index]\n",
    "    Y_batch = [Y_train[i] for i in batch_index]\n",
    "    params, cost_new = opt.step_and_cost(lambda v: cost(v, X_batch, Y_batch), params)\n",
    "    loss_history.append(cost_new)\n",
    "    if it % 10 == 0:\n",
    "        print(\"iteration: \", it, \" cost: \", cost_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Accuracy Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we trained QCNN models, let's see how well it can classify the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(predictions, labels):\n",
    "    acc = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if np.abs(l - p) < 0.5:\n",
    "            acc = acc + 1\n",
    "    return acc / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [QCNN(x, params) for x in X_test]\n",
    "accuracy = accuracy_test(predictions, Y_test)\n",
    "accuracy = accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy with QCNN model: 98.4%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test data accuracy with QCNN model: {accuracy:.3}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple QCNN model classifies the MNIST data with 98.4% accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this introductory tutorial, we only looked at QCNN with resizing (interpolation) classical preprocessing, amplitude embedding, SU4 ansatz without pooling layer, MSE loss function applied on MNIST datasets. If you want to see more of the results, look at the [original paper](https://arxiv.org/abs/2108.00661) and [code](https://github.com/takh04/QCNN?tab=readme-ov-file)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tak Hur, Leeseok Kim, and Daniel K Park. *Quantum convolutional neural network for classical data classification*. Quantum Machine Intelligence (2022).\n",
    "2. Iris Cong, Soonwon Choi, and Mikhail D. Lukin. *Quantum convolutional neural networks*. Nature Physics (2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use this code in research, please cite:\n",
    "\n",
    "```\n",
    "@article{hur2022quantum,\n",
    "  title={Quantum convolutional neural network for classical data classification},\n",
    "  author={Hur, Tak and Kim, Leeseok and Park, Daniel K},\n",
    "  journal={Quantum Machine Intelligence},\n",
    "  volume={4},\n",
    "  number={1},\n",
    "  pages={3},\n",
    "  year={2022},\n",
    "  publisher={Springer}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
